{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FORMATIVE ASSIGNMENT II: WATER QUALITY MODEL\n",
    "\n",
    "## 1. Introduction\n",
    "**Assignment**: Building a Classification Model Using Neural Networks\n",
    "\n",
    "**Objective:**\n",
    "Develop a neural network-based classification model using a provided dataset, incorporating multiple optimization techniques and ensuring equitable group contribution.\n",
    "\n",
    "**In this notebook, we will take the cleaned and imputed dataset and use it to train, test, and evaluate a deep learning model**:\n",
    "\n",
    "The key steps we'll cover are:\n",
    "1. Loading the preprocessed (imputed) dataset.\n",
    "2. Separating features and the target variable.\n",
    "3. Splitting the dataset into three distinct portions: training, validation, and testing sets. This is crucial for robust model development and evaluation.\n",
    "4. Applying feature scaling (StandardScaler) correctly after the split to prevent data leakage.\n",
    "\n",
    "**Note:** The data cleaning and imputation steps were performed in a previous notebook. \n",
    "If you'd like to review that process, please refer to: [Data Preprocessing Notebook](data_preprocessing.ipynb).\n",
    "\n",
    "**Model Details**\n",
    "\n",
    "\n",
    "| Engineer Name     | Regularizer | Optimizer | Early Stopping  | Dropout Rate | Learning Rate |\n",
    "| ----------------- | ---------------------------- | --------- | ------------------------------------------------ | ------------ | ------------- |\n",
    "| Christian Iradukunda B. | Kernel: L2 (0.006), Activity: L1 (0.006) on one hidden layer           | Nadam      |       val_loss, P=8            |   0.15      | 0.006         |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Scaling\n",
    "### 2.1 Declaring Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads a CSV file into a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The loaded DataFrame.\n",
    "\n",
    "    Raises:\n",
    "        TypeError: If file_path is not a string.\n",
    "        FileNotFoundError: If the file specified by file_path is not found.\n",
    "        Exception: For other pandas-related read errors.\n",
    "    \"\"\"\n",
    "    if not isinstance(file_path, str):\n",
    "        raise TypeError(\"file_path must be a string.\")\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Successfully loaded dataset from: {file_path}\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Error: The file '{file_path}' was not found.\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error reading CSV file '{file_path}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the dataset \n",
    "# We verify the columns, data types, and ensure that our imputation worked \n",
    "# All columns should have non-null counts matching the total number of entries.\n",
    "def display_initial_info(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Displays the first few rows and basic info of a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to inspect.\n",
    "\n",
    "    Raises:\n",
    "        TypeError: If df is not a pandas DataFrame.\n",
    "        ValueError: If df is None.\n",
    "    \"\"\"\n",
    "    print(\"===============First 5 rows:===============\")\n",
    "    print(df.head())\n",
    "    print(\"\\n===============Information:===============\")\n",
    "    df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_features_target(df: pd.DataFrame, target_column: str) -> tuple[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"\n",
    "    Separates features and the target variable from a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to separate.\n",
    "        target_column (str): The name of the target column.\n",
    "\n",
    "    Returns:\n",
    "        tuple[pd.DataFrame, pd.Series]: A tuple containing features (X) and target (y).\n",
    "\n",
    "    Raises:\n",
    "        TypeError: If df is not a DataFrame or target_column is not a string.\n",
    "        ValueError: If df is None or target_column is not found in df.columns.\n",
    "    \"\"\"\n",
    "    if target_column not in df.columns:\n",
    "        raise ValueError(f\"Target column '{target_column}' not found in DataFrame columns: {df.columns.tolist()}\")\n",
    "\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    print(f\"\\nFeatures (X) and target (y, column: '{target_column}') have been separated.\")\n",
    "    print(f\"Shape of features (X): {X.shape}\")\n",
    "    print(f\"Shape of target (y): {y.shape}\")\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X: pd.DataFrame, y: pd.Series,\n",
    "               test_size: float = 0.15,\n",
    "               val_relative_to_train_val_size: float = 0.15 / 0.85,\n",
    "               random_state: int = 42,\n",
    "               stratify_data: bool = True) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.Series, pd.Series, pd.Series]:\n",
    "    \"\"\"\n",
    "    Splits feature and target data into training, validation, and test sets.\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame): Features.\n",
    "        y (pd.Series): Target variable.\n",
    "        test_size (float): Proportion of the dataset to allocate to the test set.\n",
    "        val_relative_to_train_val_size (float): Proportion of the (train+validation) set to allocate to validation.\n",
    "        random_state (int): Seed for random number generator for reproducibility.\n",
    "        stratify_data (bool): Whether to stratify the split based on the target variable y.\n",
    "\n",
    "    Returns:\n",
    "        tuple: X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "    Raises:\n",
    "        TypeError: If X is not a DataFrame or y is not a Series.\n",
    "        ValueError: If X or y is None, or if shapes are incompatible.\n",
    "    \"\"\"\n",
    "    if len(X) != len(y):\n",
    "        raise ValueError(f\"Shape mismatch: X has {len(X)} samples, y has {len(y)} samples.\")\n",
    "\n",
    "    stratify_option_main = y if stratify_data else None\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=stratify_option_main\n",
    "    )\n",
    "\n",
    "    stratify_option_tv = y_train_val if stratify_data else None\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=val_relative_to_train_val_size,\n",
    "        random_state=random_state, stratify=stratify_option_tv\n",
    "    )\n",
    "\n",
    "    print(\"\\nData splitting completed.\")\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features(X_train: pd.DataFrame, X_val: pd.DataFrame, X_test: pd.DataFrame) -> tuple[StandardScaler, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Fits StandardScaler on X_train and transforms X_train, X_val, X_test.\n",
    "\n",
    "    Args:\n",
    "        X_train (pd.DataFrame): Training features.\n",
    "        X_val (pd.DataFrame): Validation features.\n",
    "        X_test (pd.DataFrame): Test features.\n",
    "\n",
    "    Returns:\n",
    "        tuple: The fitted scaler object, and the scaled DataFrames (X_train_scaled, X_val_scaled, X_test_scaled).\n",
    "\n",
    "    Raises:\n",
    "        TypeError: If any input is not a pandas DataFrame.\n",
    "        ValueError: If any input DataFrame is None.\n",
    "    \"\"\"\n",
    "    for df_name, df_obj in [(\"X_train\", X_train), (\"X_val\", X_val), (\"X_test\", X_test)]:\n",
    "        if not isinstance(df_obj, pd.DataFrame):\n",
    "            raise TypeError(f\"Input '{df_name}' must be a pandas DataFrame. Got {type(df_obj)}.\")\n",
    "        if df_obj is None:\n",
    "            raise ValueError(f\"Input DataFrame '{df_name}' cannot be None.\")\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    print(\"\\nFitting StandardScaler on X_train...\")\n",
    "    # Ensure X_train has data (not empty) before fitting\n",
    "    if X_train.empty:\n",
    "        raise ValueError(\"X_train is empty, cannot fit StandardScaler.\")\n",
    "    scaler.fit(X_train) # Fit ONLY on training data\n",
    "    print(\"Scaler fitted.\")\n",
    "\n",
    "    print(\"Transforming X_train, X_val, and X_test...\")\n",
    "    X_train_scaled_array = scaler.transform(X_train)\n",
    "    X_val_scaled_array = scaler.transform(X_val)\n",
    "    X_test_scaled_array = scaler.transform(X_test)\n",
    "    print(\"Transformation complete.\")\n",
    "\n",
    "    # Convert back to DataFrames\n",
    "    X_train_scaled = pd.DataFrame(X_train_scaled_array, columns=X_train.columns, index=X_train.index)\n",
    "    X_val_scaled = pd.DataFrame(X_val_scaled_array, columns=X_val.columns, index=X_val.index)\n",
    "    X_test_scaled = pd.DataFrame(X_test_scaled_array, columns=X_test.columns, index=X_test.index)\n",
    "    print(\"Scaled data converted back to DataFrames.\")\n",
    "\n",
    "    return scaler, X_train_scaled, X_val_scaled, X_test_scaled\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Feature Scaling Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded dataset from: ../data/imputed_water_potability_data.csv\n",
      "===============First 5 rows:===============\n",
      "         ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
      "0  7.036752  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
      "1  3.716080  129.422921  18630.057858     6.635246  333.073546    592.885359   \n",
      "2  8.099124  224.236259  19909.541732     9.275884  333.073546    418.606213   \n",
      "3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
      "4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
      "\n",
      "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
      "0       10.379783        86.990970   2.963135           0  \n",
      "1       15.180013        56.329076   4.500656           0  \n",
      "2       16.868637        66.420093   3.055934           0  \n",
      "3       18.436524       100.341674   4.628771           0  \n",
      "4       11.558279        31.997993   4.075075           0  \n",
      "\n",
      "===============Information:===============\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3276 entries, 0 to 3275\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   ph               3276 non-null   float64\n",
      " 1   Hardness         3276 non-null   float64\n",
      " 2   Solids           3276 non-null   float64\n",
      " 3   Chloramines      3276 non-null   float64\n",
      " 4   Sulfate          3276 non-null   float64\n",
      " 5   Conductivity     3276 non-null   float64\n",
      " 6   Organic_carbon   3276 non-null   float64\n",
      " 7   Trihalomethanes  3276 non-null   float64\n",
      " 8   Turbidity        3276 non-null   float64\n",
      " 9   Potability       3276 non-null   int64  \n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 256.1 KB\n"
     ]
    }
   ],
   "source": [
    "# Here, we load the dataset that has already undergone cleaning and imputation.\n",
    "# It's important to use the version where missing values have already been handled.\n",
    "# Path to the file which has already missing fields handled\n",
    "FILE_PATH_IMPUTED = \"../data/imputed_water_potability_data.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "df = load_data(FILE_PATH_IMPUTED)\n",
    "\n",
    "# Display the overview of the dataset\n",
    "display_initial_info(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features (X) and target (y, column: 'Potability') have been separated.\n",
      "Shape of features (X): (3276, 9)\n",
      "Shape of target (y): (3276,)\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target variable\n",
    "X, y = separate_features_target(df, \"Potability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data splitting completed.\n",
      "Shape of X_train: (2292, 9), y_train: (2292,)\n",
      "Shape of X_val: (492, 9), y_val: (492,)\n",
      "Shape of X_test: (492, 9), y_test: (492,)\n",
      "\n",
      "Proportion of samples in each set (approximate):\n",
      "Training set: 69.96%\n",
      "Validation set: 15.02%\n",
      "Test set: 15.02%\n"
     ]
    }
   ],
   "source": [
    "# Initialize split variables to None\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = [None] * 6\n",
    "\n",
    "if X is not None and y is not None:\n",
    "    try:\n",
    "        X_train, X_val, X_test, y_train, y_val, y_test = split_data(X, y, stratify_data=True)\n",
    "\n",
    "        # Display proportions\n",
    "        print(f\"Shape of X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "        print(f\"Shape of X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
    "        print(f\"Shape of X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "\n",
    "        total_samples = len(X)\n",
    "        print(\"\\nProportion of samples in each set (approximate):\")\n",
    "        print(f\"Training set: {len(X_train)/total_samples*100:.2f}%\")\n",
    "        print(f\"Validation set: {len(X_val)/total_samples*100:.2f}%\")\n",
    "        print(f\"Test set: {len(X_test)/total_samples*100:.2f}%\")\n",
    "\n",
    "    except TypeError as e:\n",
    "        raise ValueError(f\"TypeError during data splitting: {e}\")\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"ValueError during data splitting: {e}\")\n",
    "else:\n",
    "    raise ValueError(\"X or y is None.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting StandardScaler on X_train...\n",
      "Scaler fitted.\n",
      "Transforming X_train, X_val, and X_test...\n",
      "Transformation complete.\n",
      "Scaled data converted back to DataFrames.\n",
      "\n",
      "--- Verification of Scaled Training Data ---\n",
      "===============First 5 rows:===============\n",
      "            ph  Hardness    Solids  Chloramines   Sulfate  Conductivity  \\\n",
      "2766  0.292120  0.027566  0.522327     0.038376 -1.781081     -0.634797   \n",
      "2505 -0.104021  0.816164 -0.481655     0.540023 -0.954435      0.033630   \n",
      "163  -0.647064 -1.665957 -1.420733     0.308547 -1.555323     -0.140706   \n",
      "43    1.961394  0.193955 -1.379953    -0.160524  0.108557     -1.163968   \n",
      "2040 -0.022284  1.805507 -0.796542     0.846080  0.798238      0.565539   \n",
      "\n",
      "      Organic_carbon  Trihalomethanes  Turbidity  \n",
      "2766       -0.341967         0.209553  -0.180315  \n",
      "2505       -0.619904         0.161566  -1.631684  \n",
      "163         0.672902        -0.993148   0.866453  \n",
      "43          2.973166         0.352298   0.939613  \n",
      "2040        0.099535        -1.655482  -0.941722  \n",
      "\n",
      "===============Information:===============\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2292 entries, 2766 to 1559\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   ph               2292 non-null   float64\n",
      " 1   Hardness         2292 non-null   float64\n",
      " 2   Solids           2292 non-null   float64\n",
      " 3   Chloramines      2292 non-null   float64\n",
      " 4   Sulfate          2292 non-null   float64\n",
      " 5   Conductivity     2292 non-null   float64\n",
      " 6   Organic_carbon   2292 non-null   float64\n",
      " 7   Trihalomethanes  2292 non-null   float64\n",
      " 8   Turbidity        2292 non-null   float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 179.1 KB\n",
      "\n",
      "Descriptive statistics of X_train_scaled (mean ~0, std ~1):\n",
      "            ph  Hardness   Solids  Chloramines  Sulfate  Conductivity  \\\n",
      "count  2292.00   2292.00  2292.00      2292.00  2292.00       2292.00   \n",
      "mean     -0.00      0.00     0.00        -0.00     0.00         -0.00   \n",
      "std       1.00      1.00     1.00         1.00     1.00          1.00   \n",
      "min      -4.19     -4.52    -2.48        -3.43    -4.29         -3.06   \n",
      "25%      -0.56     -0.58    -0.71        -0.63    -0.46         -0.75   \n",
      "50%      -0.02      0.02    -0.11         0.01    -0.01         -0.05   \n",
      "75%       0.54      0.61     0.60         0.62     0.44          0.69   \n",
      "max       4.45      3.84     4.46         3.72     4.13          4.09   \n",
      "\n",
      "       Organic_carbon  Trihalomethanes  Turbidity  \n",
      "count         2292.00          2292.00    2292.00  \n",
      "mean             0.00             0.00       0.00  \n",
      "std              1.00             1.00       1.00  \n",
      "min             -3.04            -3.70      -3.17  \n",
      "25%             -0.67            -0.62      -0.67  \n",
      "50%             -0.02             0.02      -0.00  \n",
      "75%              0.69             0.64       0.67  \n",
      "max              3.92             3.67       3.57  \n",
      "\n",
      "Workflow complete. Data is prepared for model training.\n",
      "Prepared data sets:\n",
      "X_train_scaled: (2292, 9), y_train: (2292,)\n",
      "X_val_scaled: (492, 9), y_val: (492,)\n",
      "X_test_scaled: (492, 9), y_test: (492,)\n"
     ]
    }
   ],
   "source": [
    "scaler_object, X_train_scaled, X_val_scaled, X_test_scaled = [None] * 4\n",
    "\n",
    "if X_train is not None and X_val is not None and X_test is not None:\n",
    "    try:\n",
    "        scaler_object, X_train_scaled, X_val_scaled, X_test_scaled = scale_features(X_train, X_val, X_test)\n",
    "\n",
    "        print(\"\\n--- Verification of Scaled Training Data ---\")\n",
    "        display_initial_info(X_train_scaled)\n",
    "\n",
    "        print(\"\\nDescriptive statistics of X_train_scaled (mean ~0, std ~1):\")\n",
    "        print(X_train_scaled.describe().round(2))\n",
    "\n",
    "        print(\"\\nWorkflow complete. Data is prepared for model training.\")\n",
    "        print(\"Prepared data sets:\")\n",
    "        print(f\"X_train_scaled: {X_train_scaled.shape}, y_train: {y_train.shape if y_train is not None else 'N/A'}\")\n",
    "        print(f\"X_val_scaled: {X_val_scaled.shape}, y_val: {y_val.shape if y_val is not None else 'N/A'}\")\n",
    "        print(f\"X_test_scaled: {X_test_scaled.shape}, y_test: {y_test.shape if y_test is not None else 'N/A'}\")\n",
    "\n",
    "    except (TypeError, ValueError) as e:\n",
    "        print(f\"Error during feature scaling: {e}\")\n",
    "else:\n",
    "    print(\"Skipping feature scaling as data splits are not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building and Training a Model\n",
    "\n",
    "### 3.1. Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defnine a function to create a Keras Sequential model with specified hyperparameters\n",
    "def create_model(input_shape: tuple,\n",
    "                 dropout_rate: float = 0.15,\n",
    "                 l1_reg: float = 0.006,\n",
    "                 l2_reg: float = 0.006) -> Sequential:\n",
    "    \"\"\"\n",
    "    Creates and returns a Keras Sequential model with the specified hyperparameters.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): The shape of the input data (number of features,).\n",
    "        dropout_rate (float): The rate for the Dropout layer.\n",
    "        l1_reg (float): The factor for the L1 activity regularizer.\n",
    "        l2_reg (float): The factor for the L2 kernel regularizer.\n",
    "\n",
    "    Returns:\n",
    "        Sequential: The compiled Keras model.\n",
    "    \"\"\"\n",
    "    # Initialize the regularizers\n",
    "    kernel_regularizer = l2(l2_reg)\n",
    "    activity_regularizer = l1(l1_reg)\n",
    "\n",
    "    # Define the model architecture\n",
    "    model = Sequential([\n",
    "        # Input Layer and First Hidden Layer\n",
    "        Dense(64, activation='relu', input_shape=input_shape, name='hidden_layer_1'),\n",
    "\n",
    "        # Second Hidden Layer with specified Regularizers\n",
    "        Dense(128, activation='relu',\n",
    "              kernel_regularizer=kernel_regularizer,\n",
    "              activity_regularizer=activity_regularizer,\n",
    "              name='hidden_layer_2_with_regularizers'),\n",
    "        \n",
    "        # Dropout Layer to prevent overfitting\n",
    "        Dropout(dropout_rate, name='dropout_layer'),\n",
    "\n",
    "        # Third Hidden Layer\n",
    "        Dense(64, activation='relu', name='hidden_layer_3'),\n",
    "\n",
    "        # Output Layer\n",
    "        Dense(1, activation='sigmoid', name='output_layer')\n",
    "    ])\n",
    "\n",
    "    print(\"\\nModel architecture created successfully.\")\n",
    "    model.summary() # Print a summary of the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defnine a function to train the model\n",
    "def train_model(model: Sequential,\n",
    "                X_train: pd.DataFrame,\n",
    "                y_train: pd.Series,\n",
    "                X_val: pd.DataFrame,\n",
    "                y_val: pd.Series,\n",
    "                learning_rate: float = 0.006,\n",
    "                patience: int = 8,\n",
    "                epochs: int = 150,\n",
    "                batch_size: int = 32) -> tf.keras.callbacks.History:\n",
    "    \"\"\"\n",
    "    Compiles and trains the Keras model.\n",
    "\n",
    "    Args:\n",
    "        model (Sequential): The Keras model to train.\n",
    "        X_train, y_train: Training data and labels.\n",
    "        X_val, y_val: Validation data and labels.\n",
    "        learning_rate (float): The learning rate for the Nadam optimizer.\n",
    "        patience (int): Number of epochs with no improvement after which training will be stopped.\n",
    "        epochs (int): The maximum number of epochs to train for.\n",
    "        batch_size (int): The number of samples per gradient update.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.callbacks.History: Object containing the history of the training process.\n",
    "    \"\"\"\n",
    "    # 1. Set up the EarlyStopping callback\n",
    "    # We monitor 'val_loss' and stop if it doesn't improve for 'patience' epochs.\n",
    "    # restore_best_weights=True ensures the model weights are reset to the best ones found.\n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=patience,\n",
    "        verbose=1,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # 2. Compile the model\n",
    "    # We use the Nadam optimizer with the specified learning rate.\n",
    "    model.compile(\n",
    "        optimizer=Nadam(learning_rate=learning_rate),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')] # Tracking accuracy and AUC\n",
    "    )\n",
    "    print(\"\\nModel compiled successfully.\")\n",
    "\n",
    "    # 3. Train (fit) the model\n",
    "    print(\"Starting model training...\")\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[early_stopping_callback],\n",
    "        verbose=1 # Set to 1 to see progress bar, 2 for one line per epoch, 0 for silent\n",
    "    )\n",
    "    print(\"Model training complete.\")\n",
    "    return history\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Create and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model architecture created successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/testsolutions/Documents/school/year3/term1/water-quality-model/.venv/lib/python3.9/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_16\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_16\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hidden_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hidden_layer_2_with_regularize… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                         │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hidden_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hidden_layer_1 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hidden_layer_2_with_regularize… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)                         │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_layer (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hidden_layer_3 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,281</span> (67.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,281\u001b[0m (67.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,281</span> (67.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,281\u001b[0m (67.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model compiled successfully.\n",
      "Starting model training...\n",
      "Epoch 1/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6072 - auc: 0.4991 - loss: 2.6730 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6699\n",
      "Epoch 2/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.6149 - auc: 0.4621 - loss: 0.6685 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6699\n",
      "Epoch 3/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.5952 - auc: 0.4854 - loss: 0.6759 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6690\n",
      "Epoch 4/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - accuracy: 0.6209 - auc: 0.5021 - loss: 0.6643 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6691\n",
      "Epoch 5/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.5982 - auc: 0.4895 - loss: 0.6748 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6691\n",
      "Epoch 6/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.5932 - auc: 0.4803 - loss: 0.6769 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6738\n",
      "Epoch 7/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - accuracy: 0.6135 - auc: 0.4919 - loss: 0.6692 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6690\n",
      "Epoch 8/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.6216 - auc: 0.4764 - loss: 0.6644 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6690\n",
      "Epoch 9/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - accuracy: 0.6175 - auc: 0.4945 - loss: 0.6664 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6695\n",
      "Epoch 10/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.6184 - auc: 0.4697 - loss: 0.6659 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6697\n",
      "Epoch 11/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.6100 - auc: 0.4804 - loss: 0.6698 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6709\n",
      "Epoch 12/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.5944 - auc: 0.4877 - loss: 0.6780 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6691\n",
      "Epoch 13/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.6129 - auc: 0.4589 - loss: 0.6687 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6696\n",
      "Epoch 14/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.6163 - auc: 0.4796 - loss: 0.6678 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6721\n",
      "Epoch 15/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - accuracy: 0.6012 - auc: 0.4816 - loss: 0.6751 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6714\n",
      "Epoch 16/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.6171 - auc: 0.4899 - loss: 0.6668 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6710\n",
      "Epoch 17/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6019 - auc: 0.4832 - loss: 0.6735 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6690\n",
      "Epoch 18/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.5947 - auc: 0.4931 - loss: 0.6761 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6715\n",
      "Epoch 19/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.6097 - auc: 0.4587 - loss: 0.6719 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6725\n",
      "Epoch 20/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.6134 - auc: 0.4892 - loss: 0.6702 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6715\n",
      "Epoch 21/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.5947 - auc: 0.4604 - loss: 0.6799 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6690\n",
      "Epoch 22/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.6105 - auc: 0.4849 - loss: 0.6700 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6703\n",
      "Epoch 23/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.5884 - auc: 0.4887 - loss: 0.6774 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6701\n",
      "Epoch 24/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.6154 - auc: 0.4710 - loss: 0.6676 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6733\n",
      "Epoch 25/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.6267 - auc: 0.4644 - loss: 0.6665 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6706\n",
      "Epoch 26/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.6241 - auc: 0.4838 - loss: 0.6658 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6704\n",
      "Epoch 27/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.6022 - auc: 0.4824 - loss: 0.6732 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6707\n",
      "Epoch 28/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.6148 - auc: 0.4887 - loss: 0.6684 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6693\n",
      "Epoch 29/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.6203 - auc: 0.4945 - loss: 0.6650 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6706\n",
      "Epoch 30/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.6041 - auc: 0.4924 - loss: 0.6720 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6701\n",
      "Epoch 31/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.5891 - auc: 0.4818 - loss: 0.6776 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6713\n",
      "Epoch 32/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.6008 - auc: 0.4780 - loss: 0.6753 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6692\n",
      "Epoch 33/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - accuracy: 0.6129 - auc: 0.4562 - loss: 0.6687 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6690\n",
      "Epoch 34/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.5942 - auc: 0.4454 - loss: 0.6778 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6707\n",
      "Epoch 35/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.6067 - auc: 0.4860 - loss: 0.6721 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6701\n",
      "Epoch 36/150\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.6121 - auc: 0.4875 - loss: 0.6686 - val_accuracy: 0.6098 - val_auc: 0.5000 - val_loss: 0.6690\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Model training complete.\n",
      "\n",
      "Model training workflow has been executed.\n"
     ]
    }
   ],
   "source": [
    "# Check if the necessary data from preprocessing steps is available\n",
    "if 'X_train_scaled' in locals() and X_train_scaled is not None:\n",
    "    try:\n",
    "        # Define Hyperparameters\n",
    "        L1_VALUE = 0.03\n",
    "        L2_VALUE = 0.03\n",
    "        DROPOUT_RATE = 0.15\n",
    "        LEARNING_RATE = 0.06\n",
    "        PATIENCE = 15\n",
    "        EPOCHS = 150 # Max epochs\n",
    "        BATCH_SIZE = 32\n",
    "\n",
    "        # Create the Model\n",
    "        input_shape = (X_train_scaled.shape[1],)\n",
    "        model = create_model(\n",
    "            input_shape=input_shape,\n",
    "            dropout_rate=DROPOUT_RATE,\n",
    "            l1_reg=L1_VALUE,\n",
    "            l2_reg=L2_VALUE\n",
    "        )\n",
    "\n",
    "        # Train the Model\n",
    "        history = train_model(\n",
    "            model=model,\n",
    "            X_train=X_train_scaled,\n",
    "            y_train=y_train,\n",
    "            X_val=X_val_scaled,\n",
    "            y_val=y_val,\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            patience=PATIENCE,\n",
    "            epochs=EPOCHS,\n",
    "            # batch_size=BATCH_SIZE\n",
    "        )\n",
    "        \n",
    "        print(\"\\nModel training workflow has been executed.\")\n",
    "\n",
    "    except NameError as e:\n",
    "        print(f\"A required variable is not defined: {e}\")\n",
    "        print(\"Please ensure the data preprocessing steps have been run successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during model training: {e}\")\n",
    "else:\n",
    "    print(\"Scaled training data ('X_train_scaled') not found. Skipping model building and training.\")\n",
    "    print(\"Please ensure the previous notebook steps (loading, splitting, scaling) have been run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Model Evaluation\n",
    "\n",
    "Now that we have a trained model, the final step is to evaluate its performance on the test set (`X_test_scaled`, `y_test`).\n",
    "This data has been kept separate and has not been seen by the model during training or validation, providing an unbiased assessment of how the model would perform on new, real-world data.\n",
    "\n",
    " We will calculate the following metrics:\n",
    " - **Accuracy:** The overall percentage of correct predictions.\n",
    " - **Precision:** The ability of the model not to label a negative sample as positive. (Of all \"potable\" predictions, how many were correct?)\n",
    " - **Recall (Sensitivity):** The ability of the model to find all the positive samples. (Of all actual potable samples, how many did we find?)\n",
    " - **F1 Score:** The weighted average of Precision and Recall, providing a single metric that balances both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_performance(model: tf.keras.Model, X_test: pd.DataFrame, y_test: pd.Series):\n",
    "    \"\"\"\n",
    "    Evaluates the performance of a trained Keras model on the test set.\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): The trained Keras model.\n",
    "        X_test (pd.DataFrame): The test features.\n",
    "        y_test (pd.Series): The true test labels.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Evaluating Model on Test Set ---\")\n",
    "    \n",
    "    # Get model predictions (probabilities)\n",
    "    y_pred_proba = model.predict(X_test)\n",
    "    \n",
    "    # Convert probabilities to binary class labels (0 or 1) using a 0.5 threshold\n",
    "    y_pred_class = (y_pred_proba > 0.5).astype(\"int32\")\n",
    "    \n",
    "    # Calculate Metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred_class)\n",
    "    precision = precision_score(y_test, y_pred_class, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred_class, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred_class, zero_division=0)\n",
    "    \n",
    "    print(f\"Test Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Test Precision: {precision:.4f}\")\n",
    "    print(f\"Test Recall:    {recall:.4f}\")\n",
    "    print(f\"Test F1 Score:  {f1:.4f}\")\n",
    "    \n",
    "    # Display Classification Report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    # The report provides a breakdown of precision, recall, and f1-score for each class.\n",
    "    print(classification_report(y_test, y_pred_class, zero_division=0))\n",
    "    \n",
    "    # Display Confusion Matrix\n",
    "    print(\"Confusion Matrix:\")\n",
    "    cm = confusion_matrix(y_test, y_pred_class)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Not Potable (0)', 'Potable (1)'],\n",
    "                yticklabels=['Not Potable (0)', 'Potable (1)'])\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Model on Test Set ---\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Test Accuracy:  0.6098\n",
      "Test Precision: 0.0000\n",
      "Test Recall:    0.0000\n",
      "Test F1 Score:  0.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      1.00      0.76       300\n",
      "           1       0.00      0.00      0.00       192\n",
      "\n",
      "    accuracy                           0.61       492\n",
      "   macro avg       0.30      0.50      0.38       492\n",
      "weighted avg       0.37      0.61      0.46       492\n",
      "\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 'model' in locals() and 'X_test_scaled' in locals():\n",
    "    model_to_evaluate = model \n",
    "    \n",
    "    try:\n",
    "        evaluate_model_performance(model_to_evaluate, X_test_scaled, y_test)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during model evaluation: {e}\")\n",
    "else:\n",
    "    print(\"Could not find a trained 'model' or the 'X_test_scaled' data.\")\n",
    "    print(\"Please ensure the model training and data splitting steps were completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Results\n",
    "| Engineer Name     | Regularizer | Optimizer | Early Stopping  | Dropout Rate | Learning Rate | Accuracy | F1 Score | Recall | Precision|\n",
    "| ----------------- | ---------------------------- | --------- | ------------------------------------------------ | ------------ | ------------- | ------------ | ------------ | ------------ | ------------ |\n",
    "| Christian Iradukunda B. | Kernel: L2 (0.006), Activity: L1 (0.006) on one hidden layer | Nadam      |       val_loss, P=8            |   0.15      | 0.006         | 0.6098 | 0=0.76, 1=0.00 | 0=0.76, 1=0.00 | 0=1.00, 1=0.00 | 0=0.61, 1=0.00 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Interpretation\n",
    "The final evaluation results from the test set are definitive and demonstrate that the neural network model, in its final configuration, has failed to learn any meaningful patterns from the data.\n",
    "\n",
    "Here is a breakdown of what the metrics reveal:\n",
    "\n",
    "* **Accuracy (0.6098):** This number is misleading if viewed in isolation. It almost perfectly matches the proportion of the majority class (\"Not Potable\") in the dataset. This indicates the model has achieved this accuracy not by intelligently classifying samples, but simply by defaulting to the most frequent prediction.\n",
    "\n",
    "* **Precision, Recall, and F1 Score (all 0.0000 for Class 1, \"Potable\"):** This is the most critical finding. A score of zero across these three key metrics means the model **completely failed to identify a single \"Potable\" water sample**.\n",
    "    * **Zero Recall** means that of all the actual potable samples in the test set, none were found.\n",
    "    * **Zero Precision** means that on the rare occasion the model might have predicted \"Potable\" (which in this case was never), none would have been correct.\n",
    "\n",
    "* **Classification Report Analysis:** The report confirms the above. For the \"Potable\" class, all scores are zero. For the \"Not Potable\" class, the recall is 1.00, which confirms the model predicted every single sample as \"Not Potable.\"\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "The model has collapsed into a \"majority class classifier.\" It learned that the safest strategy to minimize its loss function was to ignore the input features entirely and always predict \"Not Potable.\" This strategy is useless for any practical application.\n",
    "\n",
    "The core reason for this failure, as evidenced by the repeated inability of the model to learn across various hyperparameter settings, is that the provided features (`ph`, `Hardness`, `Solids`, etc.) do not contain a strong enough predictive signal for this deep learning architecture to capture. The patterns are either too weak, too complex in a way the model can't grasp, or non-existent, making it impossible for the model to distinguish between the two classes effectively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

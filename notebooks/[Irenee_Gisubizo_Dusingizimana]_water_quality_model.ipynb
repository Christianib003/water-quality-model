{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOosBJz3viShv5oj4ws88xf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Christianib003/water-quality-model/blob/master/notebooks/%5BIrenee_Gisubizo_Dusingizimana%5D_water_quality_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FORMATIVE ASSIGNMENT II: WATER QUALITY MODEL\n",
        "\n",
        "## 1. Introduction\n",
        "**Assignment**: Building a Classification Model Using Neural Networks\n",
        "\n",
        "**Objective:**\n",
        "Develop a neural network-based classification model using a provided dataset, incorporating multiple optimization techniques and ensuring equitable group contribution.\n",
        "\n",
        "**In this notebook, we will take the cleaned and imputed dataset and use it to train, test, and evaluate a deep learning model**:\n",
        "\n",
        "The key steps we'll cover are:\n",
        "1. Loading the preprocessed (imputed) dataset.\n",
        "2. Separating features and the target variable.\n",
        "3. Splitting the dataset into three distinct portions: training, validation, and testing sets. This is crucial for robust model development and evaluation.\n",
        "4. Applying feature scaling (StandardScaler) correctly after the split to prevent data leakage.\n",
        "\n",
        "**Note:** The data cleaning and imputation steps were performed in a previous notebook.\n",
        "If you'd like to review that process, please refer to: [Data Preprocessing Notebook](data_preprocessing.ipynb).\n",
        "\n",
        "**Model Details**\n",
        "\n",
        "\n",
        "| Engineer Name     | Regularizer | Optimizer | Early Stopping  | Dropout Rate | Learning Rate |\n",
        "| ----------------- | ---------------------------- | --------- | ------------------------------------------------ | ------------ | ------------- |\n",
        "| Irenee Dusingizimana | L2           | AdamW      | Patience=10                 | 0.01        | 0.0001       |\n",
        "\n"
      ],
      "metadata": {
        "id": "u6XD0izX0mx_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "04iZafwC0fBf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from tensorflow.keras.optimizers import AdamW"
      ]
    }
  ]
}